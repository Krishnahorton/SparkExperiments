{"paragraphs":[{"text":"%spark2.dep\nz.load(\"/usr/hdp/current/kafka-broker/libs/kafka-clients-1.1.1.3.0.1.0-187.jar\")\n","user":"spark","dateUpdated":"2019-01-09T06:51:25+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@6e9ff461\n"}]},"apps":[],"jobName":"paragraph_1547016451009_-887242032","id":"20190109-064731_887976446","dateCreated":"2019-01-09T06:47:31+0000","dateStarted":"2019-01-09T06:51:25+0000","dateFinished":"2019-01-09T06:51:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1258"},{"title":"Produce Random data to Kafka from Spark","text":"%spark2\n   lazy val data = 1 to 2000\n   val distData =  sc.parallelize(data).mapPartitions{ p =>\n                         val r = new scala.util.Random\n                        p.map{_ =>   \n                            val device_id = 100 + r. nextInt(20)\n                            val temperature =  r. nextInt(100) *  r. nextInt(3)\n                            val timestamp =  java.time.LocalDateTime.now\n                             s\"${device_id}:${temperature}:${timestamp}\"\n                         }\n\n}.foreachPartition { partition =>\n        val bootstrapservers = \"c220-node4.squadron-labs.com:6667\"\n        val destTopic = \"devicesignal\"     \n        val kafkaProducerConfig = {\n        val p = new java.util.Properties()\n        p.setProperty(\"bootstrap.servers\", bootstrapservers)\n        p.setProperty(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\")\n        p.setProperty(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\")\n        p\n      }\n      import org.apache.kafka.clients.producer.{KafkaProducer, ProducerRecord, RecordMetadata} \n      //create Kafka producer in driver and broadcast to executor\n      val producer = new KafkaProducer[String, String](kafkaProducerConfig)\n            partition.map { record: String =>\n             producer.send(new ProducerRecord[String, String](destTopic, record))\n            }.foreach(recordMetadata => recordMetadata.get())\n           \n          }\n\nprintln(s\"${data.length} messages sent\")","user":"spark","dateUpdated":"2019-01-09T08:58:43+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true,"fontSize":9},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"20000 messages sent\ndata: scala.collection.immutable.Range.Inclusive = <lazy>\ndistData: Unit = ()\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://c220-node4.squadron-labs.com:4040/jobs/job?id=0"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1547015887029_676846873","id":"20180928-105406_1844500372","dateCreated":"2019-01-09T06:38:07+0000","dateStarted":"2019-01-09T08:58:43+0000","dateFinished":"2019-01-09T08:58:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1259"},{"text":"","user":"spark","dateUpdated":"2019-01-09T06:38:07+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"fontSize":9},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1547015887037_1288335316","id":"20161018-144007_1720066531","dateCreated":"2019-01-09T06:38:07+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1260"}],"name":"SparkKafkaProducerDemo","id":"2E3GHSFME","noteParams":{},"noteForms":{},"angularObjects":{"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}