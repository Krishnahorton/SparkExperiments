{"paragraphs":[{"title":"Produce Random data to Kafka from Spark","text":"%spark2\n   val distData =  sc.parallelize(1 to 2000).mapPartitions{ p =>\n                         val r = new scala.util.Random\n                        p.map{_ =>   \n                            val device_id = 100 + r. nextInt(20)\n                            val temperature =  r. nextInt(100) *  r. nextInt(3)\n                            val timestamp =  java.time.LocalDateTime.now\n                             s\"${device_id}:${temperature}:${timestamp}\"\n                         }\n\n}.foreachPartition { partition =>\n        val bootstrapservers = \"c120-node3.squadron-labs.com:6667\"\n        val destTopic = \"devicesignal\"     \n        val kafkaProducerConfig = {\n        val p = new java.util.Properties()\n        p.setProperty(\"bootstrap.servers\", bootstrapservers)\n        p.setProperty(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\")\n        p.setProperty(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\")\n        p\n      }\n      import org.apache.kafka.clients.producer.{KafkaProducer, ProducerRecord, RecordMetadata} \n      //create Kafka producer in driver and broadcast to executor\n      val producer = new KafkaProducer[String, String](kafkaProducerConfig)\n            partition.map { record: String =>\n             producer.send(new ProducerRecord[String, String](destTopic, record))\n            }.foreach(recordMetadata => recordMetadata.get())\n          }\n\n\n","user":"admin","dateUpdated":"2018-09-28T13:57:09+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"distData: Unit = ()\n"}]},"apps":[],"jobName":"paragraph_1538132046492_-858980153","id":"20180928-105406_1844500372","dateCreated":"2018-09-28T10:54:06+0000","dateStarted":"2018-09-28T13:58:00+0000","dateFinished":"2018-09-28T13:58:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1526"},{"text":"","dateUpdated":"2018-09-28T10:51:53+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1538131913562_-77519031","id":"20161018-144007_1720066531","dateCreated":"2018-09-28T10:51:53+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1528","user":"admin"}],"name":"Labs / Spark 2.x /SparkKafkaProducerDemo","id":"2DRQAQTYK","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":true,"looknfeel":"default","personalizedMode":"false","cronExecutingUser":"admin","cron":"0 0/1 * * * ?"},"info":{}}