{"paragraphs":[{"title":"Add dependencies","text":"%spark2.dep\nz.reset()\nz.load(\"org.apache.spark:spark-streaming-kafka-0-10_2.11:2.3.0\")\n","user":"admin","dateUpdated":"2018-09-28T13:15:29+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"enabled":true,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@2fb589d0\n"}]},"apps":[],"jobName":"paragraph_1538136324613_73831109","id":"20180928-071305_750869571","dateCreated":"2018-09-28T12:05:24+0000","dateStarted":"2018-09-28T12:57:48+0000","dateFinished":"2018-09-28T12:58:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:461"},{"title":"Initialise StreamingContext","text":"%spark2\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.streaming.kafka010._\nimport org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent\nimport org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe\n\nval topic = \"devicesignal\"\nval brokers = \"c120-node3.squadron-labs.com:6667\"\n\nval kafkaParams = Map[String, Object](\n    \"bootstrap.servers\" -> brokers,\n    \"key.deserializer\" -> classOf[StringDeserializer],\n    \"value.deserializer\" -> classOf[StringDeserializer],\n    \"group.id\" -> \"StreamTestGroup\",\n    \"auto.offset.reset\" -> \"latest\",\n    \"enable.auto.commit\" -> (false: java.lang.Boolean)\n  )\n  \n  val topics = Array(topic)\n  val streamingContext = new StreamingContext(sc, Seconds(120))\n  \n  val stream = KafkaUtils.createDirectStream[String, String](\n  streamingContext,\n  PreferConsistent,\n  Subscribe[String, String](topics, kafkaParams))\n  \n  val schemaString = \"device_id,temperature,timestamp\"\n  import org.apache.spark.sql.types._\n  val tableSchema = StructType( schemaString.split(\",\").map(fieldName => StructField(fieldName, StringType, true)))\n  \n  stream.foreachRDD { (rdd: org.apache.spark.rdd.RDD[org.apache.kafka.clients.consumer.ConsumerRecord[String,String]], time: org.apache.spark.streaming.Time) =>\n  val rowRDD = rdd.map(r => org.apache.spark.sql.Row.fromSeq(new String(r.value).split(\":\")))\n  val wordsDF = sqlContext.createDataFrame(rowRDD,tableSchema)\n  wordsDF.registerTempTable(\"realTimeTable\")\n  \n    val offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges\n    stream.asInstanceOf[CanCommitOffsets].commitAsync(offsetRanges)\n  }\n\n","user":"admin","dateUpdated":"2018-09-28T13:26:34+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":false,"language":"scala"},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.streaming.kafka010._\nimport org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent\nimport org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe\ntopic: String = devicesignal\nbrokers: String = c120-node3.squadron-labs.com:6667\nkafkaParams: scala.collection.immutable.Map[String,Object] = Map(key.deserializer -> class org.apache.kafka.common.serialization.StringDeserializer, auto.offset.reset -> latest, group.id -> StreamTestGroup, bootstrap.servers -> c120-node3.squadron-labs.com:6667, enable.auto.commit -> false, value.deserializer -> class org.apache.kafka.common.serialization.StringDeserializer)\ntopics: Array[String] = Array(devicesignal)\nstreamingContext: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@1b43afec\nstream: org.apache.spark.streaming.dstream.InputDStream[org.apache.kafka.clients.consumer.ConsumerRecord[String,String]] = org.apache.spark.streaming.kafka010.DirectKafkaInputDStream@262980c2\nschemaString: String = device_id,temperature,timestamp\nimport org.apache.spark.sql.types._\ntableSchema: org.apache.spark.sql.types.StructType = StructType(StructField(device_id,StringType,true), StructField(temperature,StringType,true), StructField(timestamp,StringType,true))\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]},"apps":[],"jobName":"paragraph_1538136324615_74600607","id":"20160331-233830_541232082","dateCreated":"2018-09-28T12:05:24+0000","dateStarted":"2018-09-28T13:00:45+0000","dateFinished":"2018-09-28T13:01:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:462"},{"text":"%spark2\n\n  // Start the context\n  streamingContext.start()\n","user":"admin","dateUpdated":"2018-09-28T13:16:10+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"},"editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1538136324615_74600607","id":"20180928-100621_1081082753","dateCreated":"2018-09-28T12:05:24+0000","dateStarted":"2018-09-28T13:01:12+0000","dateFinished":"2018-09-28T13:01:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:463"},{"text":"%sql\nselect device_id, avg(temperature) max_temp from realTimeTable group by device_id, 'timestamp' order by 'timestamp'\n","user":"admin","dateUpdated":"2018-09-28T13:58:08+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"device_id","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"max_temp","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true,"editorSetting":{"language":"sql","editOnDblClick":false},"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"device_id\tmax_temp\n101\t47.057575757575755\n112\t51.375838926174495\n113\t50.23432343234323\n107\t48.13840830449827\n110\t48.245847176079735\n100\t50.20979020979021\n118\t49.473509933774835\n104\t51.82165605095541\n102\t49.148148148148145\n111\t48.86435331230284\n103\t52.51546391752577\n115\t49.784126984126985\n108\t51.370860927152314\n117\t50.98679867986799\n114\t47.734082397003746\n106\t46.224489795918366\n116\t49.369565217391305\n105\t48.63758389261745\n109\t51.217791411042946\n119\t52.95876288659794\n"}]},"apps":[],"jobName":"paragraph_1538136324616_72676863","id":"20180928-103708_649998107","dateCreated":"2018-09-28T12:05:24+0000","dateStarted":"2018-09-28T13:57:30+0000","dateFinished":"2018-09-28T13:57:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:464"},{"text":"%spark2\nstreamingContext.stop(stopSparkContext=false, stopGracefully=true)\n","user":"admin","dateUpdated":"2018-09-28T13:00:18+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1538136324616_72676863","id":"20180928-102211_1204937749","dateCreated":"2018-09-28T12:05:24+0000","dateStarted":"2018-09-28T13:00:18+0000","dateFinished":"2018-09-28T13:01:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:465"},{"text":"","dateUpdated":"2018-09-28T12:05:24+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1538136324617_72292114","id":"20161018-144007_1720066531","dateCreated":"2018-09-28T12:05:24+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:466"}],"name":"Labs / Spark 2.x /SparkKafkaConsumerDemo","id":"2DT3AM26A","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":true,"looknfeel":"default","personalizedMode":"false"},"info":{}}